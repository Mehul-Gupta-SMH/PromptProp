import fastapi
from fastapi import HTTPException
from starlette.responses import JSONResponse

app = fastapi.FastAPI()

@app.get("/")
async def root():
    return JSONResponse({"message": "Welcome to the PromptProp Backend API!"})


@app.get("/health-check")
async def health_check():
    return JSONResponse({"status": "healthy"})

@app.get("/jury")
async def jury(agent_config: dict, generated_answer: dict, reference_answer: dict, experiment_id: str):
    """
    Endpoint for jury processing. This is a placeholder for the actual implementation.
    :param agent_config: The input provided to the model.
    :param generated_answer: The answer generated by the model.
    :param reference_answer: The reference answer for comparison.
    :param experiment_id: The identifier for the experiment whose jury processing is to be conducted.

    :return: Evaluation results or feedback based on the jury's assessment of the generated answer against the
    reference answer.
    """
    raise HTTPException(status_code=501, detail="Jury processing not implemented yet.")

@app.get("/evaluate")
async def evaluate(agent_config: dict, jury_eval: dict, experiment_id: str):
    """
    Endpoint for evaluation processing. This is a placeholder for the actual implementation.
    :param agent_config: The input provided to the model.
    :param jury_eval: The evaluation provided by the jury.
    :param experiment_id: The identifier for the experiment whose jury processing is to be conducted.

    :return: Refined prompts or feedback based on the jury evaluation.
    """
    raise HTTPException(status_code=501, detail="Evaluation processing not implemented yet.")

@app.get("/evaluation_metrics")
async def evaluation_metrics(experiment_id: str):
    """
    Endpoint for evaluation metrics processing. This is a placeholder for the actual implementation.
    :param experiment_id: The identifier for the experiment whose evaluation metrics are to be processed.

    :return: Metrics or insights derived from the evaluation process.
    """
    raise HTTPException(status_code=501, detail="Evaluation metrics processing not implemented yet.")

@app.post("/train_data")
async def train_data(experiment_id: str, data: dict):
    """
    Endpoint for training data processing. This is a placeholder for the actual implementation.
    :param experiment_id: The identifier for the experiment whose training data is to be processed.
    :param data: The training data to be used for model training or fine-tuning.

    :return: Confirmation of data receipt and any relevant information about the training process.
    """
    raise HTTPException(status_code=501, detail="Training data processing not implemented yet.")

@app.post("/validation_data")
async def validation_data(experiment_id: str, data: dict):
    """
    Endpoint for Validation data processing. This is a placeholder for the actual implementation.
    :param experiment_id: The identifier for the experiment whose training data is to be processed.
    :param data: The data to be used for model validation.

    :return: Confirmation of data receipt and any relevant information about the validation process.
    """
    raise HTTPException(status_code=501, detail="Validation data processing not implemented yet.")

@app.post("/test_data")
async def test_data(experiment_id: str, data: dict):
    """
    Endpoint for Test data processing. This is a placeholder for the actual implementation.
    :param experiment_id: The identifier for the experiment whose training data is to be processed.
    :param data: The data to be used for model testing.

    :return: Confirmation of data receipt and any relevant information about the testing process.
    """
    raise HTTPException(status_code=501, detail="Test data processing not implemented yet.")

# def run():
#     import uvicorn
#     uvicorn.run(app, host="0.0.0.0", port=8000)clear
