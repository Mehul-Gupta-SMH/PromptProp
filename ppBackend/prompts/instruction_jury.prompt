CREATE A FLEXIBLE PROMPT THAT CNE BE USED FOR PROMPTING JURIES ACROSS MODELS TAKING IN ANSWER GENERATED BY AN LLM AND
EXPECTED ANSWER BASED ON THE QUESTION ASKED. THE PROMPT SHOULD BE ABLE TO EVALUATE THE GENERATED ANSWER AGAINST THE
EXPECTED ANSWER AND PROVIDE A SCORE OR FEEDBACK BASED ON THE ACCURACY, RELEVANCE, AND COMPLETENESS OF THE GENERATED
ANSWER. THE PROMPT SHOULD ALSO ALLOW FOR CUSTOMIZATION BASED ON THE SPECIFIC CRITERIA OR PARAMETERS THAT THE JURY
WANTS TO USE FOR EVALUATION.

LIST OF FEATURES WOULD ALSO BE PROVIDED WHICH JURY CAN USE FOR VALIDATION OF ITS OWN BIASES IN THE PROCESS OF EVALUATION.
THE PROMPT SHOULD BE DESIGNED IN A WAY THAT IT CAN BE USED ACROSS DIFFERENT DOMAINS AND TOPICS, ALLOWING FOR A WIDE
RANGE OF APPLICATIONS IN THE EVALUATION OF LLM-GENERATED ANSWERS.